# -*- coding: utf-8 -*-
"""my-code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nC9SmLPFQKzSnEMQWS0E1xa0nRfdfc4d

## Mounting Google Drive

In this section, we will mount Google Drive to our Colab environment. This allows us to access files stored in Google Drive directly from the Colab notebook. This is particularly useful for loading datasets, saving models, and accessing other resources stored in Google Drive.

###  Import the Drive Module

We start by importing the `drive` module from `google.colab`. This module provides the necessary functions to mount Google Drive.
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# note : my working drive path is /content/drive/MyDrive/internship

"""## Installing Required Libraries

In this section, we will install the necessary libraries for audio processing. Specifically, we will install `librosa`, a Python package for music and audio analysis. `librosa` provides the building blocks necessary to create music information retrieval systems.

### Install `librosa`

We use the `pip` package manager to install `librosa`. The `!` at the beginning of the command allows us to run shell commands directly from the Colab notebook.

"""

# Install required libraries
!pip install librosa

"""
### Import Libraries

Import the necessary libraries: `librosa` for audio processing, `numpy` for numerical operations, `os` for file path operations, and `pandas` for data manipulation.
"""

import librosa
import numpy as np
import os
import pandas as pd
from tensorflow.keras.models import Sequential
import matplotlib.pyplot as plt
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout,Conv2D, MaxPooling2D,Reshape
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.models import load_model
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Input
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import VGG16
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger

"""## Download the Dataset

Use `wget` to download the dataset from the provided URL.

"""

# Download the dataset

# !wget -O files-archive.zip https://zenodo.org/api/records/2552860/files-archive

# !unzip /content/drive/MyDrive/internship/FSDKaggle2018.meta.zip -d /content/drive/MyDrive/internship

"""# **Loading Audio Data**(Analysis)"""

file= '/content/drive/MyDrive/internship/FSDKaggle2018.audio_train/00044347.wav'

signal , sr = librosa.load(file, sr = 4096 )
print(sr)

plt.figure(figsize=(15,17))
librosa.display.waveshow(signal)
plt.title('waveform')
plt.xlabel('time')
plt.ylabel('amplitutde')
plt.show()

display(signal,sr)

!pip install IPython
import IPython.display as ipd

ipd.Audio(signal, rate=sr)

"""SFTF Calculation"""

hop_length =512
n_fft = 8192

hop_length_duration = float(hop_length)/sr
n_fft_duration = float(n_fft)/sr

stf = librosa.stft(signal , n_fft = n_fft, hop_length = hop_length )

spectrogram = np.abs(stf)

librosa.display.specshow(spectrogram, sr=sr, hop_length=hop_length)
plt.xlabel("Time")
plt.ylabel("Frequency")
plt.colorbar(format="%+2.0f dB")
plt.title("Spectrogram (dB)")

log_spectrogram = librosa.amplitude_to_db(spectrogram)

librosa.display.specshow(log_spectrogram, sr=sr, hop_length=hop_length)
plt.xlabel("Time")
plt.ylabel("Frequency")
plt.colorbar(format="%+2.0f dB")
plt.title("Log_Spectrogram (dB)")

"""MFCC (Mel-Frequency Cepstral Coefficients)"""

MFCCS = librosa.feature.mfcc(y = signal, sr = sr, n_fft = n_fft, hop_length = hop_length)

librosa.display.specshow(MFCCS, sr= sr, hop_length = hop_length)
plt.xlabel('Time')
plt.ylabel('MFCC')
plt.colorbar()
plt.title('MFCC')
plt.show()

"""Mel Frequency Spectrogram Calculation"""

mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=128, fmax=8000)
mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)

librosa.display.specshow(mel_spectrogram_db, sr=sr, hop_length=hop_length)
plt.xlabel("Time")
plt.ylabel("MFCC coefficients")
plt.colorbar()
plt.title("MFCCs")


plt.show()

!pip install resampy --upgrade
import resampy
import librosa

"""## Load Metadata and Set Data Paths

Load the metadata CSV files and set the paths to the training and testing data directories.

"""

import pandas as pd

# Specify the correct CSV path
CSV_PATH = "/content/drive/MyDrive/internship/FSDKaggle2018.audio_train/FSDKaggle2018.meta/train_post_competition.csv"

# Read the CSV file and print the first few rows for verification
df = pd.read_csv(CSV_PATH)
print(df.head())

import os

def list_files_in_directory(directory):
    """List files in a directory for debugging purposes."""
    for dirpath, _, filenames in os.walk(directory):
        for f in filenames:
            print(f"Found file: {os.path.join(dirpath, f)}")

# Specify the correct directory path where the audio files are stored
AUDIO_FOLDER_PATH = "/content/drive/MyDrive/internship/FSDKaggle2018.audio_train"

# List files in the directory
list_files_in_directory(AUDIO_FOLDER_PATH)

"""## Feature Extraction Function

Define a function to extract MFCC features from an audio file.

"""

# Install resampy
!pip install resampy

# Function to extract features from an audio file
def extract_features(file_path):
    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')
    print(audio,sample_rate)
    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
    mfccs_processed = np.mean(mfccs.T,axis=0)
    return mfccs_processed

# import resampy
# file_path = '/content/drive/MyDrive/internship/FSDKaggle2018.audio_train/00044347.wav'
# data = extract_features(file_path)

!pip install resampy --upgrade
import resampy
import librosa

"""## Load Dataset and Extract Features

This code iterates through the metadata, loads each audio file, extracts MFCC features, and stores them along with their labels. The output is two lists, `train_features` and `test_features`, containing the extracted features and corresponding labels for the training and testing datasets, respectively.
"""

# i have run this code once and save in in google drive; so no need to run again

# # Load dataset and extract features
# train_features = []
# test_features = []

# for _, row in train_meta.iterrows():
#     # this will take only file path
#     file_path = os.path.join(train_dir, row['fname'])

#     if os.path.exists(file_path):
#         # print("here",file_path)
#         data = extract_features(file_path)
#         # print("extract data : ",data)
#         train_features.append([data, row['label']])

# for _, row in test_meta.iterrows():
#     file_path = os.path.join(test_dir, row['fname'])
#     if os.path.exists(file_path):
#         data = extract_features(file_path)
#         test_features.append([data, row['label']])

import os
import json
import numpy as np
import librosa
import pandas as pd

# Constants
SAMPLE_RATE = 22050  # Sample rate
N_MFCC = 13  # Number of MFCCs to extract
MAX_MFCC_VECTORS = 130  # Max number of MFCC vectors to pad/truncate to

def save_mfcc_from_csv(csv_path, audio_folder_path, json_path, num_mfcc=N_MFCC, n_fft=2048, hop_length=512):
    """Extracts MFCCs from audio files listed in a CSV and saves them into a json file along with labels.

    :param csv_path (str): Path to CSV file with filenames and labels
    :param audio_folder_path (str): Path to folder containing audio files
    :param json_path (str): Path to json file used to save MFCCs
    :param num_mfcc (int): Number of coefficients to extract
    :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples
    :param hop_length (int): Sliding window for FFT. Measured in # of samples
    :return:
    """

    # Dictionary to store mapping, labels, and MFCCs
    data = {
        "mapping": [],
        "labels": [],
        "mfcc": []
    }

    # List files in audio folder for debugging
    print("Listing files in audio folder for debugging:")
    list_files_in_directory(audio_folder_path)

    # Read the CSV file
    df = pd.read_csv(csv_path)

    # Ensure the CSV has the necessary columns
    if "fname" not in df.columns or "label" not in df.columns:
        raise ValueError("CSV file must contain 'fname' and 'label' columns")

    # Process each row in the CSV
    for index, row in df.iterrows():
        file_path = os.path.join(audio_folder_path, row["fname"])
        label = row["label"]

        if not os.path.isfile(file_path):
            print(f"File does not exist: {file_path}")
            continue

        try:
            # Load audio file
            signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)

            # Extract MFCC
            mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length).T

            # Pad or truncate MFCC to ensure uniform length
            if len(mfcc) > MAX_MFCC_VECTORS:
                mfcc = mfcc[:MAX_MFCC_VECTORS]
            elif len(mfcc) < MAX_MFCC_VECTORS:
                pad_width = MAX_MFCC_VECTORS - len(mfcc)
                mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')

            # Ensure all MFCC arrays have the same length
            assert mfcc.shape[0] == MAX_MFCC_VECTORS, f"MFCC shape mismatch: {mfcc.shape[0]} != {MAX_MFCC_VECTORS}"

            # Store MFCC feature
            data["mfcc"].append(mfcc.tolist())
            data["labels"].append(label)
            if label not in data["mapping"]:
                data["mapping"].append(label)

            print(f"Processed {file_path}")

        except Exception as e:
            print(f"Error processing {file_path}: {e}")

    # Check if data was collected
    if not data["mfcc"] or not data["labels"]:
        print("No data was collected. Please check your dataset and preprocessing steps.")
        return

    # Save MFCCs to json file
    with open(json_path, "w") as fp:
        json.dump(data, fp, indent=4)

    print("Data successfully saved to JSON file!")

if __name__ == "__main__":
    CSV_PATH = "/content/drive/MyDrive/internship/FSDKaggle2018.audio_train/FSDKaggle2018.meta/train_post_competition.csv"
    AUDIO_FOLDER_PATH = "/content/drive/MyDrive/internship/FSDKaggle2018.audio_train"
    JSON_PATH = "/content/drive/MyDrive/internship/path_to_save_json.json"  # Replace with your desired JSON path
    save_mfcc_from_csv(CSV_PATH, AUDIO_FOLDER_PATH, JSON_PATH)

import json
import os

JSON_PATH = "/content/drive/MyDrive/internship/path_to_save_json.json"

# Create the directory if it doesn't exist
os.makedirs("/content/drive/MyDrive/internship", exist_ok=True)

# Load the JSON data from the file
with open(JSON_PATH, "r") as f:
    json_data = json.load(f)

# Save the JSON data to the new location
with open("/content/drive/MyDrive/internship/path_to_save_json.json", "w") as f:
    json.dump(json_data, f)

print("JSON data successfully saved to /content/drive/MyDrive/internship")

# save this list data in a file with same name as list at this loaction /content/drive/MyDrive/internship

# import pickle

# with open('/content/drive/MyDrive/internship/train_features.pkl', 'wb') as f:
#   pickle.dump(train_features, f)

# with open('/content/drive/MyDrive/internship/test_features.pkl', 'wb') as f:
#   pickle.dump(test_features, f)

# # loading features data from save file
# with open('/content/drive/MyDrive/internship/train_features.pkl', 'rb') as f:
#   train_features = pickle.load(f)

# with open('/content/drive/MyDrive/internship/test_features.pkl', 'rb') as f:
#   test_features = pickle.load(f)

# len(train_features),len(test_features)

"""---"""

# Constants
SAMPLE_RATE = 4096  # Sample rate
N_MFCC = 13  # Number of MFCCs to extract
MAX_MFCC_VECTORS = 130  # Max number of MFCC vectors to pad/truncate to

def load_data(json_path):
    """Loads data from JSON file."""
    with open(json_path, "r") as fp:
        data = json.load(fp)

    X = np.array(data["mfcc"])
    y = np.array(data["labels"])

    return X, y, data["mapping"]

def preprocess_data(X, y):
    """Preprocesses the data for CNN input."""
    # Encode the string labels as integers
    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(y)

    # Ensure labels are one-hot encoded
    y = to_categorical(y, num_classes=len(np.unique(y)))

    # Add a channel dimension to the features
    X = X[..., np.newaxis]

    return X, y, label_encoder

"""## Build, Compile, and Train the Model

Define a Sequential model with dense and dropout layers, compile it with the Adam optimizer and categorical crossentropy loss, and train it on the training data.

## Build the Model

Define a Sequential model with dense and dropout layers.
"""

# # Build the model
# model = Sequential([
#     Flatten(input_shape=(x_train.shape[1],)),
#     Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
#     BatchNormalization(),
#     Dropout(0.5),
#     Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
#     BatchNormalization(),
#     Dropout(0.5),
#     Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
#     BatchNormalization(),
#     Dropout(0.5),
#     Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
#     BatchNormalization(),
#     Dropout(0.5),
#     Dense(len(np.unique(y_train)), activation='softmax')
# ])

# Build the model
# model = Sequential([
#     Flatten(input_shape=(x_train.shape[1],)),
#     Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),
#     BatchNormalization(),
#     Dropout(0.5),
#     Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),
#     BatchNormalization(),
#     Dropout(0.5),
#     Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),
#     BatchNormalization(),
#     Dropout(0.5),
#     Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),
#     BatchNormalization(),
#     Dropout(0.5),
#     Dense(len(np.unique(y_train)), activation='softmax')
# ])

# model = Sequential([
#     Flatten(input_shape=(x_train.shape[1],)),
#     Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),
#     BatchNormalization(),
#     Dropout(0.3),
#     Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),
#     BatchNormalization(),
#     Dropout(0.3),
#     Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),
#     BatchNormalization(),
#     Dropout(0.3),
#     Dense(len(np.unique(y_train)), activation='softmax')
# ])

# def build_cnn_model(input_shape, num_classes):
#     """Builds a CNN model for MFCC classification."""
#     model = tf.keras.Sequential([
#         tf.keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=input_shape), # Reduced kernel size to (2,2)
#         tf.keras.layers.MaxPooling2D((2, 2)),
#         tf.keras.layers.Conv2D(64, (2, 2), activation='relu'), # Reduced kernel size to (2,2)
#         tf.keras.layers.MaxPooling2D((2, 2)),
#         tf.keras.layers.Flatten(),

#         tf.keras.layers.Dense(512, activation='relu'),
#         tf.keras.layers.Dense(256, activation='relu'),
#         tf.keras.layers.Dense(128, activation='relu'),

#         tf.keras.layers.Dense(num_classes, activation='softmax')
#     ])
#     return model

# # accuracy = 56
# def build_cnn_model(input_shape, num_classes):
#     """Builds a deeper CNN model for MFCC classification."""
#     model = tf.keras.Sequential([
#         tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
#         tf.keras.layers.BatchNormalization(),
#         tf.keras.layers.MaxPooling2D((2, 2)),
#         tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
#         tf.keras.layers.BatchNormalization(),
#         tf.keras.layers.MaxPooling2D((2, 2)),
#         tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
#         tf.keras.layers.BatchNormalization(),
#         tf.keras.layers.MaxPooling2D((2, 2)),
#         tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),
#         tf.keras.layers.BatchNormalization(),
#         tf.keras.layers.MaxPooling2D((2, 2)),
#         tf.keras.layers.Flatten(),
#         tf.keras.layers.Dense(512, activation='relu'),
#         tf.keras.layers.Dropout(0.5),
#         tf.keras.layers.Dense(256, activation='relu'),
#         tf.keras.layers.Dropout(0.5),
#         tf.keras.layers.Dense(128, activation='relu'),
#         tf.keras.layers.Dense(num_classes, activation='softmax')
#     ])
#     return model

def build_cnn_model(input_shape, num_classes):
    """Builds a deeper CNN model for MFCC classification."""
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D((2, 2), padding='same'),
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D((2, 2), padding='same'),
        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D((2, 2), padding='same'),
        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D((2, 2), padding='same'),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(num_classes, activation='softmax')
    ])
    return model

"""Define the JSON path:"""

JSON_PATH = "/content/drive/MyDrive/internship/path_to_save_json.json"

"""Load and preprocess data:"""

X, y, mapping = load_data(JSON_PATH)
X, y, label_encoder = preprocess_data(X, y)

"""Print the shapes of features and labels to ensure correctness:"""

print(f'Features shape: {X.shape}')
print(f'Labels shape: {y.shape}')

"""Split the data into training and testing sets:"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=20)

"""
### Model Architecture Summary"""

# model.summary()

"""## Compile the Model

Compile the model using the Adam optimizer and categorical crossentropy loss function.

"""

# Step 5: Build the CNN model
input_shape = X_train.shape[1:]
num_classes = y_train.shape[1]
model = build_cnn_model(input_shape, num_classes)

# Compile the model
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

"""## Train the Model

Train the model on the training data for 50 epochs with a batch size of 32, and validate on the validation data.

x_train.shape, y_train.shape
"""

# check = list(set(y_train))
# for i in range(len(check)):
#   print(i,check[i])

# print(x_train[:])

# x_val.shape,y_val.shape

# print("total training data : ",x_train.shape[0]+x_val.shape[0])

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)

class BatchLogger(tf.keras.callbacks.Callback):
    def on_train_begin(self, logs=None):
        self.batch_losses = []
        self.batch_acc = []
        self.val_losses = []
        self.val_acc = []

    def on_batch_end(self, batch, logs=None):
        self.batch_losses.append(logs.get('loss'))
        self.batch_acc.append(logs.get('accuracy'))

    def on_epoch_end(self, epoch, logs=None):
        self.val_losses.append(logs.get('val_loss'))
        self.val_acc.append(logs.get('val_accuracy'))

batch_logger = BatchLogger()

# Train the model
history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, callbacks=[early_stopping, batch_logger,reduce_lr])

# Evaluate the model
evaluation = model.evaluate(X_test, y_test)
print(f"Test Loss: {evaluation[0]}")
print(f"Test Accuracy: {evaluation[1]}")

"""## Save the Model

Save the trained model to Google Drive.

"""

# Save the model

model.save('/content/drive/MyDrive/internship/audio_model.h5')

# Optionally save the label encoder
import pickle
with open('label_encoder.pkl', 'wb') as file:
    pickle.dump(label_encoder, file)

"""## Load the Model

Load the saved model from Google Drive.

"""

# Load the trained model
model = load_model('/content/drive/MyDrive/internship/audio_model.h5')

# Load the label encoder
with open('label_encoder.pkl', 'rb') as file:
    label_encoder = pickle.load(file)

if __name__ == "__main__":
    CSV_PATH_1= "/content/drive/MyDrive/internship/FSDKaggle2018.meta/test_post_competition_scoring_clips.csv"
    AUDIO_FOLDER_PATH_1 = "/content/drive/MyDrive/internship/FSDKaggle2018.audio_test"
    JSON_PATH_1 = "/content/drive/MyDrive/internship/path_to_save_test_json.json"
    save_mfcc_from_csv(CSV_PATH_1, AUDIO_FOLDER_PATH_1, JSON_PATH_1)

JSON_PATH_1 = "/content/drive/MyDrive/internship/path_to_save_test_json.json"

# !cp /content/drive/MyDrive/internship/path_to_save_test_json.json /content/drive/MyDrive/internship/FSDKaggle2018.audio_test/

def preprocess_data1(X, y):
    """Preprocesses the data for CNN input."""
    # Encode the string labels as integers
    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(y)

    # Ensure labels are one-hot encoded
    y = to_categorical(y, num_classes=len(np.unique(y)))

    # Add a channel dimension to the features
    X = X[..., np.newaxis]

    return X, y, label_encoder



xtest, ytest, mapping = load_data(JSON_PATH_1)
xtest, ytest, label_encoder = preprocess_data1(xtest, ytest)

# Evaluate the model on the test data
evaluation = model.evaluate(xtest, ytest)
print(f"Test Loss: {evaluation[0]}")
print(f"Test Accuracy: {evaluation[1]}")

# Make predictions on the test data
y_pred = model.predict(xtest)
y_pred_labels = np.argmax(y_pred, axis=1)

# Decode the predicted labels if needed
y_pred_labels_decoded = label_encoder.inverse_transform(y_pred_labels)

# Create a DataFrame to display true and predicted labels
results = pd.DataFrame({
    'True Label': ytest
    ,'Predicted Label': y_pred_labels_decoded
})

# Display the evaluation results
evaluation_results = pd.DataFrame({
    'Metric': ['Loss', 'Accuracy'],
    'Value': [evaluation[0], evaluation[1]]
})

print("Evaluation Results:")
print(evaluation_results)

print("\nSample Predictions:")
print(results.head(40))



def plot_training_history(history):
    """Plots the training and validation loss and accuracy."""
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(len(acc))

    plt.figure(figsize=(12, 8))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, acc, 'b', label='Training accuracy')
    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
    plt.title('Training and Validation Accuracy')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(epochs, loss, 'b', label='Training loss')
    plt.plot(epochs, val_loss, 'r', label='Validation loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.show()

plot_training_history(history)

def plot_batch_history(batch_logger):
    """Plots accuracy/loss for training/validation set as a function of the batches

    :param batch_logger: Instance of BatchLogger containing batch metrics
    :return:
    """

    fig, axs = plt.subplots(2, figsize=(12, 8))

    # Plot training accuracy and validation accuracy
    axs[0].plot(batch_logger.batch_acc, label="Train Accuracy")
    axs[0].plot(
        [i * len(batch_logger.batch_acc) // len(batch_logger.val_acc) for i in range(len(batch_logger.val_acc))],
        batch_logger.val_acc,
        label="Test Accuracy"
    )
    axs[0].set_ylabel("Accuracy")
    axs[0].legend(loc="lower right")
    axs[0].set_title("Accuracy Evaluation")

    # Plot training loss and validation loss
    axs[1].plot(batch_logger.batch_losses, label="Train Loss")
    axs[1].plot(
        [i * len(batch_logger.batch_losses) // len(batch_logger.val_losses) for i in range(len(batch_logger.val_losses))],
        batch_logger.val_losses,
        label="Test Loss"
    )
    axs[1].set_ylabel("Loss")
    axs[1].set_xlabel("Batch")
    axs[1].legend(loc="upper right")
    axs[1].set_title("Loss Evaluation")

    plt.tight_layout()
    plt.show()

# Plot batch-level history
plot_batch_history(batch_logger)

import pandas as pd
results = pd.DataFrame({
    'True Label': ytest,
    'Predicted Label': y_pred_labels_decoded
})

# Save the results DataFrame
results.to_csv('results.csv', index=False)

# Save evaluation metrics
evaluation_results = pd.DataFrame({
    'Metric': ['Loss', 'Accuracy'],
    'Value': [evaluation[0], evaluation[1]]
})

evaluation_results.to_csv('evaluation_results.csv', index=False)

"""# **Improved model **"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator